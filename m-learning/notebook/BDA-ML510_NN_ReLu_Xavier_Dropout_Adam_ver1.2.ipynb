{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry 4.0 의 중심, AI - ML&DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='right'><font size=2 color='gray'>Machine Learning & Deep Learning with TensorFlow @ <font color='blue'><a href='https://www.facebook.com/jskim.kr'>FB / jskim.kr</a></font>, 김진수</font></div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect10. NN, ReLu, Xavier, Dropout, and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from images import bigpycraft_ai as bpc\n",
    "from IPython.display import Image \n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "### Examples : https://github.com/aymericdamien/TensorFlow-Examples\n",
    "//-->"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "import time\n",
    "import os\n",
    "\n",
    "def chk_processting_time(start_time, end_time):\n",
    "    process_time = end_time - start_time\n",
    "    p_time = int(process_time)\n",
    "    p_min = p_time // 60\n",
    "    p_sec = p_time %  60\n",
    "    print('처리시간 : {p_min}분 {p_sec}초 경과되었습니다.'.format(\n",
    "            p_min = p_min, \n",
    "            p_sec = p_sec\n",
    "        ))\n",
    "    return process_time\n",
    "//-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00AAAA'> \n",
    "# MNIST Dataset Introduction\n",
    "<br>\n",
    "Most examples are using MNIST dataset of handwritten digits. It has 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image, so each sample is represented as a matrix of size 28x28 with values from 0 to 1.\n",
    "\n",
    "### Overview\n",
    "\n",
    "![MNIST Digits](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "### Usage\n",
    "In our examples, we are using TensorFlow [input_data.py](https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/input_data.py) script to load that dataset.\n",
    "It is quite useful for managing our data, and handle:\n",
    "\n",
    "- Dataset downloading\n",
    "\n",
    "- Loading the entire dataset into numpy array: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3-50\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f5f295f1b6a3>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Load data\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00CCCC'> \n",
    "- A \"next_batch\" function that can iterate over the whole dataset and return only the desired fraction of the dataset samples (in order to save memory and avoid to load the entire dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the next 64 images array and labels\n",
    "batch_X, batch_Y = mnist.train.next_batch(64)\n",
    "batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def chk_processting_time(start_time, end_time):\n",
    "    process_time = end_time - start_time\n",
    "    p_time = int(process_time)\n",
    "    p_min = p_time // 60\n",
    "    p_sec = p_time %  60\n",
    "    print('처리시간 : {p_min}분 {p_sec}초 경과되었습니다.'.format(\n",
    "            p_min = p_min, \n",
    "            p_sec = p_sec\n",
    "        ))\n",
    "    return process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "time.sleep(3)\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리시간 : 0분 3초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0003879070281982"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### 1. Softmax classifier for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-6-a821cfaead4a>:31: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review : Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders, 784(=28*28)\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Signature: tf.reduce_mean(input_tensor, axis=None, keep_dims=False, name=None, reduction_indices=None)\n",
    "Docstring:\n",
    "Computes the mean of elements across dimensions of a tensor.\n",
    "\n",
    "Args:\n",
    "  input_tensor: The tensor to reduce. Should have numeric type.\n",
    "  axis: The dimensions to reduce. If `None` (the default), reduces all dimensions.\n",
    "  keep_dims: If true, retains reduced dimensions with length 1.\n",
    "  name: A name for the operation (optional).\n",
    "  reduction_indices: The old (deprecated) name for axis.\n",
    "\n",
    "Returns:\n",
    "  The reduced tensor."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Signature: tf.nn.softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\n",
    "Docstring:\n",
    "Computes softmax cross entropy between `logits` and `labels`.\n",
    "\n",
    "Args:\n",
    "  _sentinel: Used to prevent positional parameters. Internal, do not use.\n",
    "  labels: Each row `labels[i]` must be a valid probability distribution.\n",
    "  logits: Unscaled log probabilities.\n",
    "  dim: The class dimension. Defaulted to -1 which is the last dimension.\n",
    "  name: A name for the operation (optional).\n",
    "\n",
    "Returns:\n",
    "  A 1-D `Tensor` of length `batch_size` of the same type as `logits` with the\n",
    "  softmax cross entropy loss."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Init signature: tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "Docstring:     \n",
    "Optimizer that implements the Adam algorithm.\n",
    "\n",
    "Args:\n",
    "  learning_rate: A Tensor or a floating point value.  The learning rate.\n",
    "  beta1: A float value or a constant float tensor.\n",
    "         The exponential decay rate for the 1st moment estimates.\n",
    "  beta2: A float value or a constant float tensor.\n",
    "         The exponential decay rate for the 2nd moment estimates.\n",
    "  epsilon: A small constant for numerical stability.\n",
    "  use_locking: If True use locks for update operations.\n",
    "  name: Optional name for the operations created when applying gradients.\n",
    "        Defaults to \"Adam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d5788f8924444bb56e5a6791865a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001  | cost = 5.745170984\n",
      "Epoch: 0002  | cost = 1.780056711\n",
      "Epoch: 0003  | cost = 1.122778637\n",
      "Epoch: 0004  | cost = 0.872012248\n",
      "Epoch: 0005  | cost = 0.738203186\n",
      "Epoch: 0006  | cost = 0.654728888\n",
      "Epoch: 0007  | cost = 0.596023608\n",
      "Epoch: 0008  | cost = 0.552216820\n",
      "Epoch: 0009  | cost = 0.518254961\n",
      "Epoch: 0010  | cost = 0.491113188\n",
      "Epoch: 0011  | cost = 0.468347537\n",
      "Epoch: 0012  | cost = 0.449374351\n",
      "Epoch: 0013  | cost = 0.432675659\n",
      "Epoch: 0014  | cost = 0.418828158\n",
      "Epoch: 0015  | cost = 0.406128930\n",
      "\n",
      "Learning Finished!\n",
      "처리시간 : 0분 9초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.513186931610107"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training_epochs, mnist.train.num_examples, total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9023\n",
      "Label:  [4]\n",
      "Prediction:  [4]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQFCEHwiK8ANBEX4gKMIPBEX4gaD+H26Z5QuARilnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a00136a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### 2. NN(Newral Nets) for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST and NN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "# b1 = tf.Variable(tf.random_normal([256]))\n",
    "# L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "# b2 = tf.Variable(tf.random_normal([256]))\n",
    "# L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "# b3 = tf.Variable(tf.random_normal([10]))\n",
    "# hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# tf Graph input\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "# Softmax loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))     \n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8026796a63194d74b4f9a117cf4a33f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001  | cost = 168.871117528\n",
      "Epoch: 0002  | cost = 39.789018199\n",
      "Epoch: 0003  | cost = 25.078855662\n",
      "Epoch: 0004  | cost = 17.581257204\n",
      "Epoch: 0005  | cost = 12.949745178\n",
      "Epoch: 0006  | cost = 9.672311279\n",
      "Epoch: 0007  | cost = 7.251559166\n",
      "Epoch: 0008  | cost = 5.489999496\n",
      "Epoch: 0009  | cost = 4.080529510\n",
      "Epoch: 0010  | cost = 3.032799814\n",
      "Epoch: 0011  | cost = 2.280402585\n",
      "Epoch: 0012  | cost = 1.826971169\n",
      "Epoch: 0013  | cost = 1.487424602\n",
      "Epoch: 0014  | cost = 1.108632946\n",
      "Epoch: 0015  | cost = 0.960463530\n",
      "\n",
      "Learning Finished!\n",
      "처리시간 : 0분 27초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.125386714935303"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 55000, 550)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_epochs, mnist.train.num_examples, total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9443\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a007bb0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "### 3. Xavier initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법 : initializer=tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Lab 10 MNIST and Xavier\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023b23a07d584dbfbf494158908e1ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001  | cost = 0.302049108\n",
      "Epoch: 0002  | cost = 0.120434554\n",
      "Epoch: 0003  | cost = 0.077402316\n",
      "Epoch: 0004  | cost = 0.056101177\n",
      "Epoch: 0005  | cost = 0.040522710\n",
      "Epoch: 0006  | cost = 0.031933484\n",
      "Epoch: 0007  | cost = 0.025075606\n",
      "Epoch: 0008  | cost = 0.019702032\n",
      "Epoch: 0009  | cost = 0.016768747\n",
      "Epoch: 0010  | cost = 0.017060622\n",
      "Epoch: 0011  | cost = 0.011450966\n",
      "Epoch: 0012  | cost = 0.009874320\n",
      "Epoch: 0013  | cost = 0.011352131\n",
      "Epoch: 0014  | cost = 0.010574085\n",
      "Epoch: 0015  | cost = 0.008389076\n",
      "\n",
      "Learning Finished!\n",
      "처리시간 : 0분 26초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.245803356170654"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9788\n",
      "Label:  [2]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf25NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a5d567f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "<marquee><font size=3 color='brown'>The BigpyCraft find the information to design valuable society with Technology & Craft.</font></marquee>\n",
    "<div align='right'><font size=2 color='gray'> &lt; The End &gt; </font></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
