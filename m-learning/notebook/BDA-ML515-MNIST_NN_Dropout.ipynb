{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry 4.0 의 중심, AI - ML&DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='right'><font size=2 color='gray'>Machine Learning & Deep Learning with TensorFlow @ <font color='blue'><a href='https://www.facebook.com/jskim.kr'>FB / jskim.kr</a></font>, 김진수</font></div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect10. NN, ReLu, Xavier, Dropout, and Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. More deep & dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from images import bigpycraft_ai as bpc\n",
    "from IPython.display import Image \n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def chk_processting_time(start_time, end_time):\n",
    "    process_time = end_time - start_time\n",
    "    p_time = int(process_time)\n",
    "    p_min = p_time // 60\n",
    "    p_sec = p_time %  60\n",
    "    print('처리시간 : {p_min}분 {p_sec}초 경과되었습니다.'.format(\n",
    "            p_min = p_min, \n",
    "            p_sec = p_sec\n",
    "        ))\n",
    "    return process_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3-50\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a66d1ca25872>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-3-a66d1ca25872>:59: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST and Dropout\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# dropout (keep_prob) rate  0.5~0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.449984572\n",
      "Epoch: 0002 cost = 0.172536668\n",
      "Epoch: 0003 cost = 0.128767682\n",
      "Epoch: 0004 cost = 0.107104696\n",
      "Epoch: 0005 cost = 0.092661290\n",
      "Epoch: 0006 cost = 0.084650072\n",
      "Epoch: 0007 cost = 0.078430915\n",
      "Epoch: 0008 cost = 0.067991683\n",
      "Epoch: 0009 cost = 0.064345236\n",
      "Epoch: 0010 cost = 0.058371233\n",
      "Epoch: 0011 cost = 0.057193876\n",
      "Epoch: 0012 cost = 0.053716918\n",
      "Epoch: 0013 cost = 0.050594152\n",
      "Epoch: 0014 cost = 0.049474327\n",
      "Epoch: 0015 cost = 0.047428535\n",
      "Learning Finished!\n",
      "처리시간 : 1분 52초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "112.74387168884277"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "chk_processting_time(time1, time2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9791\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b4573aada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))    # must be 1\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "<marquee><font size=3 color='brown'>The BigpyCraft find the information to design valuable society with Technology & Craft.</font></marquee>\n",
    "<div align='right'><font size=2 color='gray'> &lt; The End &gt; </font></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
