{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry 4.0 의 중심, AI - ML&DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='right'><font size=2 color='gray'>Machine Learning & Deep Learning with TensorFlow @ <font color='blue'><a href='https://www.facebook.com/jskim.kr'>FB / jskim.kr</a></font>, 김진수</font></div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect10. NN, ReLu, Xavier, Dropout, and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from images import bigpycraft_ai as bpc\n",
    "from IPython.display import Image \n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "### Examples : https://github.com/aymericdamien/TensorFlow-Examples\n",
    "//-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def chk_processting_time(start_time, end_time):\n",
    "    process_time = end_time - start_time\n",
    "    p_time = int(process_time)\n",
    "    p_min = p_time // 60\n",
    "    p_sec = p_time %  60\n",
    "    print('처리시간 : {p_min}분 {p_sec}초 경과되었습니다.'.format(\n",
    "            p_min = p_min, \n",
    "            p_sec = p_sec\n",
    "        ))\n",
    "    return process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00AAAA'> \n",
    "# MNIST Dataset Introduction\n",
    "<br>\n",
    "Most examples are using MNIST dataset of handwritten digits. It has 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image, so each sample is represented as a matrix of size 28x28 with values from 0 to 1.\n",
    "\n",
    "### Overview\n",
    "\n",
    "![MNIST Digits](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "### Usage\n",
    "In our examples, we are using TensorFlow [input_data.py](https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/input_data.py) script to load that dataset.\n",
    "It is quite useful for managing our data, and handle:\n",
    "\n",
    "- Dataset downloading\n",
    "\n",
    "- Loading the entire dataset into numpy array: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3-50\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-f5f295f1b6a3>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3-50\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Load data\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00CCCC'> \n",
    "- A \"next_batch\" function that can iterate over the whole dataset and return only the desired fraction of the dataset samples (in order to save memory and avoid to load the entire dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the next 64 images array and labels\n",
    "batch_X, batch_Y = mnist.train.next_batch(64)\n",
    "batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "time.sleep(3)\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리시간 : 0분 3초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.00020170211792"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### 1. Softmax classifier for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-7-a821cfaead4a>:31: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review : Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders, 784(=28*28)\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "Signature: tf.nn.softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\n",
    "Docstring:\n",
    "Computes softmax cross entropy between `logits` and `labels`.\n",
    "\n",
    "Args:\n",
    "  _sentinel: Used to prevent positional parameters. Internal, do not use.\n",
    "  labels: Each row `labels[i]` must be a valid probability distribution.\n",
    "  logits: Unscaled log probabilities.\n",
    "  dim: The class dimension. Defaulted to -1 which is the last dimension.\n",
    "  name: A name for the operation (optional).\n",
    "\n",
    "Returns:\n",
    "  A 1-D `Tensor` of length `batch_size` of the same type as `logits` with the\n",
    "  softmax cross entropy loss.\n",
    "\n",
    "//-->"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "Init signature: tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "Docstring:     \n",
    "Optimizer that implements the Adam algorithm.\n",
    "\n",
    "Args:\n",
    "  learning_rate: A Tensor or a floating point value.  The learning rate.\n",
    "  beta1: A float value or a constant float tensor.\n",
    "         The exponential decay rate for the 1st moment estimates.\n",
    "  beta2: A float value or a constant float tensor.\n",
    "         The exponential decay rate for the 2nd moment estimates.\n",
    "  epsilon: A small constant for numerical stability.\n",
    "  use_locking: If True use locks for update operations.\n",
    "  name: Optional name for the operations created when applying gradients.\n",
    "        Defaults to \"Adam\".\n",
    "\n",
    "//-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e0a62a7a59487a81824059e48f03b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001  | cost = 5.745170984\n",
      "Epoch: 0002  | cost = 1.780056711\n",
      "Epoch: 0003  | cost = 1.122778637\n",
      "Epoch: 0004  | cost = 0.872012248\n",
      "Epoch: 0005  | cost = 0.738203186\n",
      "Epoch: 0006  | cost = 0.654728888\n",
      "Epoch: 0007  | cost = 0.596023608\n",
      "Epoch: 0008  | cost = 0.552216820\n",
      "Epoch: 0009  | cost = 0.518254961\n",
      "Epoch: 0010  | cost = 0.491113188\n",
      "Epoch: 0011  | cost = 0.468347537\n",
      "Epoch: 0012  | cost = 0.449374351\n",
      "Epoch: 0013  | cost = 0.432675659\n",
      "Epoch: 0014  | cost = 0.418828158\n",
      "Epoch: 0015  | cost = 0.406128930\n",
      "\n",
      "Learning Finished!\n",
      "처리시간 : 0분 8초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.920405864715576"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training_epochs, mnist.train.num_examples, total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9023\n",
      "Label:  [8]\n",
      "Prediction:  [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2949ea36d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### 2. NN(Neural Nets) for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST and NN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "# b1 = tf.Variable(tf.random_normal([256]))\n",
    "# L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "# b2 = tf.Variable(tf.random_normal([256]))\n",
    "# L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "# b3 = tf.Variable(tf.random_normal([10]))\n",
    "# hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# tf Graph input\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "# Softmax loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))     \n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81da148eb2a64161ba5464c83cc5b445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001  | cost = 168.871117528\n",
      "Epoch: 0002  | cost = 39.789018199\n",
      "Epoch: 0003  | cost = 25.078855662\n",
      "Epoch: 0004  | cost = 17.581257204\n",
      "Epoch: 0005  | cost = 12.949745178\n",
      "Epoch: 0006  | cost = 9.672311279\n",
      "Epoch: 0007  | cost = 7.251559166\n",
      "Epoch: 0008  | cost = 5.489999496\n",
      "Epoch: 0009  | cost = 4.080529510\n",
      "Epoch: 0010  | cost = 3.032799814\n",
      "Epoch: 0011  | cost = 2.280402585\n",
      "Epoch: 0012  | cost = 1.826971169\n",
      "Epoch: 0013  | cost = 1.487424602\n",
      "Epoch: 0014  | cost = 1.108632946\n",
      "Epoch: 0015  | cost = 0.960463530\n",
      "\n",
      "Learning Finished!\n",
      "처리시간 : 0분 25초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.98979926109314"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 55000, 550)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_epochs, mnist.train.num_examples, total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9443\n",
      "Label:  [8]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2949fb58b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "### 3. Xavier initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법 : initializer=tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Lab 10 MNIST and Xavier\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6986798f71146539605c26b79b8061e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001  | cost = 0.302049108\n",
      "Epoch: 0002  | cost = 0.120434554\n",
      "Epoch: 0003  | cost = 0.077402316\n",
      "Epoch: 0004  | cost = 0.056101177\n",
      "Epoch: 0005  | cost = 0.040522710\n",
      "Epoch: 0006  | cost = 0.031933484\n",
      "Epoch: 0007  | cost = 0.025075606\n",
      "Epoch: 0008  | cost = 0.019702032\n",
      "Epoch: 0009  | cost = 0.016768747\n",
      "Epoch: 0010  | cost = 0.017060622\n",
      "Epoch: 0011  | cost = 0.011450966\n",
      "Epoch: 0012  | cost = 0.009874320\n",
      "Epoch: 0013  | cost = 0.011352131\n",
      "Epoch: 0014  | cost = 0.010574085\n",
      "Epoch: 0015  | cost = 0.008389076\n",
      "\n",
      "Learning Finished!\n",
      "처리시간 : 0분 25초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.75314164161682"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9788\n",
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2949e62be48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "<marquee><font size=3 color='brown'>The BigpyCraft find the information to design valuable society with Technology & Craft.</font></marquee>\n",
    "<div align='right'><font size=2 color='gray'> &lt; The End &gt; </font></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
